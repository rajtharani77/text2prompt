{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12431983,"sourceType":"datasetVersion","datasetId":7841792},{"sourceId":12433264,"sourceType":"datasetVersion","datasetId":7842647},{"sourceId":12434452,"sourceType":"datasetVersion","datasetId":7843447},{"sourceId":12439725,"sourceType":"datasetVersion","datasetId":7846968},{"sourceId":12442948,"sourceType":"datasetVersion","datasetId":7849114},{"sourceId":12442969,"sourceType":"datasetVersion","datasetId":7849132}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T18:09:02.210106Z","iopub.execute_input":"2025-07-11T18:09:02.210488Z","iopub.status.idle":"2025-07-11T18:10:24.100089Z","shell.execute_reply.started":"2025-07-11T18:09:02.210463Z","shell.execute_reply":"2025-07-11T18:10:24.098994Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import ast\nimport re\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nclass ProfessionalCodeSummarizer:\n    \"\"\"High-quality code summarizer using specialized models\"\"\"\n    \n    def __init__(self):\n        try:\n            # Medium-sized model specialized for code (220M parameters)\n            self.tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n            self.model = AutoModelForSeq2SeqLM.from_pretrained(\n                \"Salesforce/codet5-base\",\n                device_map=\"auto\",\n                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n            )\n            print(\"✅ Loaded CodeT5-base model for code understanding\")\n        except Exception as e:\n            print(f\"⚠️ Model load failed: {str(e)}\")\n            self.model = None\n    \n    def analyze(self, file_path: str) -> dict:\n        \"\"\"Comprehensive code analysis with structured output\"\"\"\n        try:\n            with open(file_path, \"r\") as f:\n                content = f.read()\n        except Exception as e:\n            return {\n                \"structural\": f\"File read error: {str(e)}\",\n                \"functional\": \"\"\n            }\n        \n        is_ast_dump = \"Module(\" in content and \"FunctionDef(\" in content\n        \n        return {\n            \"structural\": self._structural_analysis(content, is_ast_dump),\n            \"functional\": self._functional_analysis(content, is_ast_dump),\n            \"deep\": self._deep_analysis(content, is_ast_dump) if self.model else \"Deep analysis unavailable\"\n        }\n    \n    def _structural_analysis(self, content: str, is_ast_dump: bool) -> str:\n        \"\"\"Detailed structural analysis of code\"\"\"\n        analysis = [\"🔍 STRUCTURAL ANALYSIS\"]\n        \n        # Import analysis\n        imports = self._extract_imports(content, is_ast_dump)\n        analysis.append(f\"• Detected Imports: {len(imports)}\")\n        if imports:\n            analysis.append(\"\\n📦 KEY IMPORTS:\")\n            analysis.extend(f\"  - {imp}\" for imp in imports[:5])\n        \n        # Function analysis\n        functions = self._extract_functions(content, is_ast_dump)\n        analysis.append(f\"\\n• Detected Functions: {len(functions)}\")\n        if functions:\n            analysis.append(\"\\n🧰 CORE FUNCTIONS:\")\n            analysis.extend(f\"  - {func}\" for func in functions[:5])\n        \n        # Class analysis\n        classes = self._extract_classes(content, is_ast_dump)\n        analysis.append(f\"\\n• Detected Classes: {len(classes)}\")\n        if classes:\n            analysis.append(\"\\n🏛️ CLASS STRUCTURES:\")\n            for cls in classes[:3]:\n                analysis.append(f\"  - {cls['name']}\")\n                for method in cls['methods'][:3]:\n                    analysis.append(f\"    • {method}()\")\n        \n        return \"\\n\".join(analysis)\n    \n    def _functional_analysis(self, content: str, is_ast_dump: bool) -> str:\n        \"\"\"Functional summary with deep insights\"\"\"\n        analysis = [\"🚀 FUNCTIONAL SUMMARY\"]\n        \n        # Domain detection\n        domains = set()\n        if \"streamlit\" in content: domains.add(\"web application\")\n        if \"requests\" in content: domains.add(\"API integration\")\n        if \"os\" in content: domains.add(\"system operations\")\n        if \"flask\" in content: domains.add(\"web framework\")\n        domain_str = ', '.join(domains) or 'general purpose'\n        analysis.append(f\"This appears to be a {domain_str} application with the following key components:\")\n        \n        # Function purposes\n        functions = self._extract_functions(content, is_ast_dump)\n        for func in functions[:5]:\n            name = func.split('(')[0]\n            purpose = self._infer_function_purpose(name, content)\n            analysis.append(f\"  - {name}: {purpose}\")\n        \n        # Class purposes\n        classes = self._extract_classes(content, is_ast_dump)\n        for cls in classes[:3]:\n            name = cls['name']\n            purpose = self._infer_class_purpose(name, content)\n            analysis.append(f\"  - {name} (class): {purpose}\")\n            for method in cls['methods'][:3]:\n                method_purpose = self._infer_function_purpose(method, content)\n                analysis.append(f\"    • {method}: {method_purpose}\")\n        \n        return \"\\n\".join(analysis)\n    def _deep_analysis(self, content: str, is_ast_dump: bool) -> str:\n        \"\"\"Generate professional technical summary with validation\"\"\"\n        try:\n            # Prepare optimized context\n            context = self._prepare_analysis_context(content, is_ast_dump)\n        \n            # Create focused prompt\n            prompt = self._create_analysis_prompt(context, is_ast_dump)\n        \n            # Generate initial analysis\n            raw_analysis = self._generate_raw_analysis(prompt)\n        \n        # Refine and validate the output\n            return self._refine_analysis(raw_analysis, context)\n        except Exception as e:\n            return f\"Deep analysis failed: {str(e)}\"\n\n    def _prepare_analysis_context(self, content: str, is_ast_dump: bool) -> str:\n        \"\"\"Prepare clean context for analysis\"\"\"\n    # Remove noisy patterns\n        patterns_to_remove = [\n            r\"ctx=[^)]+\\)\", \n            r\"value=[^,]+,\", \n            r\"slice=[^,]+,\", \n            r\"attr=[^,]+,\"\n        ]\n        clean_content = content\n        for pattern in patterns_to_remove:\n            clean_content = re.sub(pattern, \"\", clean_content)\n    \n    # Extract key components\n        key_components = []\n        if is_ast_dump:\n        # For AST dumps, focus on structure\n            key_components.extend(self._extract_imports(clean_content, True)[:3])\n            key_components.extend(self._extract_functions(clean_content, True)[:3])\n        else:\n        # For source code, focus on functionality\n            key_components.extend(self._extract_imports(clean_content, False)[:3])\n            key_components.extend(self._extract_functions(clean_content, False)[:3])\n            classes = self._extract_classes(clean_content, False)\n            for cls in classes[:2]:\n                key_components.append(f\"Class {cls['name']} with methods: {', '.join(cls['methods'][:2])}\")\n    \n        return \"\\n\".join(key_components) + \"\\n\\n\" + clean_content[:2000]\n\n    def _create_analysis_prompt(self, context: str, is_ast_dump: bool) -> str:\n        \"\"\"Create focused prompt for technical analysis\"\"\"\n        if is_ast_dump:\n            return f\"\"\"Analyze this code structure and provide a concise technical summary covering:\n            - Primary purpose of the code\n            - Key architectural components\n            - Data flow patterns\n            - Notable implementation techniques\n        \n            Structure summary:\n            {context}\n        \n            Technical summary (8-9 sentences):\"\"\"\n        else:\n            return f\"\"\"Provide a professional technical analysis of this code:\n            1. Core functionality and business purpose\n            2. Architectural patterns used\n            3. Critical dependencies\n            4. Security considerations\n            5. Optimization opportunities\n        \n            Write in complete sentences, avoid code snippets.\n        \n            Code context:\n            {context}\n        \n            Technical analysis (8-9 sentences):\"\"\"\n\n    def _generate_raw_analysis(self, prompt: str) -> str:\n        \"\"\"Generate initial analysis with controlled parameters\"\"\"\n        inputs = self.tokenizer(\n            prompt,\n            return_tensors=\"pt\",\n            max_length=512,\n            truncation=True\n        ).to(self.model.device)\n    \n        outputs = self.model.generate(\n            **inputs,\n            max_new_tokens=300,\n            temperature=0.3,  # Lower for more focused output\n            do_sample=True,\n            top_p=0.9,\n            repetition_penalty=1.5,  # Strongly prevent repetition\n            no_repeat_ngram_size=3,\n            early_stopping=True\n        )\n        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    def _refine_analysis(self, raw_analysis: str, context: str) -> str:\n        \"\"\"Refine and validate the technical analysis\"\"\"\n    # Remove incomplete sentences\n        sentences = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', raw_analysis) if s.strip()]\n        complete_sentences = [s for s in sentences if re.search(r'[.!?]$', s)]\n    \n    # Filter out code regurgitation\n        filtered_sentences = []\n        code_keywords = [\"ctx=\", \"value=\", \"attr=\", \"slice=\", \"return\", \"def \", \"class \"]\n        for sentence in complete_sentences:\n            if not any(kw in sentence for kw in code_keywords):\n                if len(sentence.split()) > 5:  # Filter out fragments\n                    filtered_sentences.append(sentence)\n    \n        # Ensure technical focus\n        technical_terms = [\"architecture\", \"functionality\", \"pattern\", \"security\", \"optimize\", \"dependency\"]\n        if not any(term in \" \".join(filtered_sentences).lower() for term in technical_terms):\n            # Fallback to rule-based summary if no technical content\n            return self._rule_based_technical_summary(context)\n    \n        return \" \".join(filtered_sentences[:6])  # Return 4-6 sentences\n\n    def _rule_based_technical_summary(self, context: str) -> str:\n        \"\"\"Fallback rule-based technical summary\"\"\"\n        summary = []\n    \n    # Detect key technical aspects\n        if \"API\" in context or \"http\" in context:\n            summary.append(\"The code implements API integration, handling remote service communication.\")\n    \n        if \"session_state\" in context or \"session\" in context:\n            summary.append(\"State management is implemented using session-based storage.\")\n    \n        if \"error\" in context or \"except\" in context:\n            summary.append(\"Error handling mechanisms are included for robustness.\")\n    \n        if \"security\" in context or \"auth\" in context:\n            summary.append(\"Security considerations include authentication and authorization.\")\n    \n        if \"model\" in context or \"AI\" in context:\n            summary.append(\"The system integrates with AI models for intelligent processing.\")\n    \n        if not summary:\n            summary.append(\"This code implements core business logic with standard technical patterns.\")\n    \n        return \" \".join(summary)\n \n  \n    def _infer_function_purpose(self, func_name: str, content: str) -> str:\n        \"\"\"Intelligent function purpose inference\"\"\"\n        # Contextual pattern matching\n        if \"generate_response\" in func_name:\n            return \"Handles AI API communication and response generation\"\n        elif \"detect_language\" in func_name:\n            return \"Identifies programming languages from text input\"\n        elif \"oauth\" in func_name:\n            return \"Manages OAuth authentication flows\"\n        elif \"header\" in func_name:\n            return \"Creates and configures HTTP headers for API requests\"\n        elif \"health\" in func_name:\n            return \"Provides system health status and monitoring\"\n        elif \"signup\" in func_name:\n            return \"Handles user registration processes\"\n        elif \"submit\" in func_name:\n            return \"Processes form submissions and data ingestion\"\n        elif \"init\" in func_name or \"setup\" in func_name:\n            return \"Initializes application components and configurations\"\n        elif \"handle\" in func_name:\n            return \"Manages core business logic and workflows\"\n        elif \"process\" in func_name:\n            return \"Transforms and manipulates data\"\n        elif \"get\" in func_name:\n            return \"Retrieves data from internal or external sources\"\n        elif \"create\" in func_name or \"make\" in func_name:\n            return \"Constructs new objects or resources\"\n        elif \"send\" in func_name or \"post\" in func_name:\n            return \"Transmits data to external systems or APIs\"\n        \n        # Fallback based on context\n        if \"api\" in content.lower() and \"key\" in content.lower():\n            return \"Manages API communication and authentication\"\n        if \"request\" in content.lower() and \"response\" in content.lower():\n            return \"Handles HTTP request/response cycles\"\n        if \"database\" in content.lower() or \"db\" in content.lower():\n            return \"Manages database interactions and data persistence\"\n        \n        return \"Performs core application operations\"\n    \n    def _infer_class_purpose(self, class_name: str, content: str) -> str:\n        \"\"\"Intelligent class purpose inference\"\"\"\n        if \"client\" in class_name.lower():\n            return \"API client for external service communication\"\n        if \"service\" in class_name.lower():\n            return \"Business logic service implementation\"\n        if \"handler\" in class_name.lower():\n            return \"Request/response processing component\"\n        if \"model\" in class_name.lower():\n            return \"Data representation and structure definition\"\n        if \"controller\" in class_name.lower():\n            return \"Orchestrates application workflow\"\n        if \"view\" in class_name.lower():\n            return \"Presentation layer component\"\n        if \"util\" in class_name.lower() or \"helper\" in class_name.lower():\n            return \"Utility functions and helper methods\"\n        if \"middleware\" in class_name.lower():\n            return \"Intercepts and processes requests/responses\"\n        if \"adapter\" in class_name.lower():\n            return \"Interface between incompatible components\"\n        if \"factory\" in class_name.lower():\n            return \"Creates and manages object instances\"\n        \n        # Context-based inference\n        if \"http\" in content.lower() and \"session\" in content.lower():\n            return \"Manages HTTP sessions and connections\"\n        if \"database\" in content.lower() and \"connection\" in content.lower():\n            return \"Database connection and ORM management\"\n        \n        return \"Encapsulates related functionality and state\"\n    \n    def _extract_imports(self, content: str, is_ast_dump: bool) -> list:\n        \"\"\"Robust import extraction\"\"\"\n        imports = []\n        if is_ast_dump:\n            # AST dump parsing\n            for match in re.finditer(r\"Import(?:From)?\\(\\s*.*?names=\\[([^\\]]+)\\]\", content):\n                for alias in re.finditer(r\"alias\\(name='([^']+)'\", match.group(1)):\n                    imports.append(alias.group(1))\n        else:\n            # Source code parsing\n            try:\n                tree = ast.parse(content)\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for alias in node.names:\n                            imports.append(f\"import {alias.name}\")\n                    elif isinstance(node, ast.ImportFrom):\n                        module = node.module or \"\"\n                        for alias in node.names:\n                            imports.append(f\"from {module} import {alias.name}\")\n            except SyntaxError:\n                # Fallback regex for source code\n                for match in re.finditer(r\"^\\s*(?:from\\s+(\\S+)\\s+)?import\\s+(?:[^\\s,]+(?:\\s*,\\s*[^\\s,]+)*)\", content, re.MULTILINE):\n                    if match.group(1):\n                        imports.append(f\"from {match.group(1)} import ...\")\n                    else:\n                        imports.append(f\"import {match.group(0).split()[-1]}\")\n        return list(set(imports))[:20]  # Limit to top 20\n    \n    def _extract_functions(self, content: str, is_ast_dump: bool) -> list:\n        \"\"\"Comprehensive function extraction\"\"\"\n        functions = []\n        if is_ast_dump:\n            # AST dump parsing\n            for match in re.finditer(r\"FunctionDef\\(\\s*name='([^']+)',\\s*args=arguments\\(args=\\[([^\\]]+)\\]\", content):\n                func_name = match.group(1)\n                args = []\n                for arg_match in re.finditer(r\"arg\\(\\s*arg='([^']+)'\", match.group(2)):\n                    args.append(arg_match.group(1))\n                functions.append(f\"{func_name}({', '.join(args)})\")\n        else:\n            # Source code parsing\n            try:\n                tree = ast.parse(content)\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.FunctionDef):\n                        args = [arg.arg for arg in node.args.args]\n                        functions.append(f\"{node.name}({', '.join(args)})\")\n            except SyntaxError:\n                # Fallback regex for source code\n                for match in re.finditer(r\"def\\s+(\\w+)\\s*\\(([^)]*)\\)\", content):\n                    func_name = match.group(1)\n                    args = [a.strip() for a in match.group(2).split(',') if a.strip()]\n                    functions.append(f\"{func_name}({', '.join(args)})\")\n        return functions\n    \n    def _extract_classes(self, content: str, is_ast_dump: bool) -> list:\n        \"\"\"Extract class information\"\"\"\n        classes = []\n        if is_ast_dump:\n            # AST dump parsing\n            for match in re.finditer(r\"ClassDef\\(\\s*name='([^']+)'.*?body=\\[([^\\]]+)\\]\", content, re.DOTALL):\n                class_name = match.group(1)\n                methods = []\n                # Extract methods from class body\n                for method_match in re.finditer(r\"FunctionDef\\(\\s*name='([^']+)'\", match.group(2)):\n                    methods.append(method_match.group(1))\n                classes.append({\"name\": class_name, \"methods\": methods})\n        else:\n            # Source code parsing\n            try:\n                tree = ast.parse(content)\n                for node in ast.walk(tree):\n                    if isinstance(node, ast.ClassDef):\n                        methods = []\n                        for item in node.body:\n                            if isinstance(item, ast.FunctionDef):\n                                methods.append(item.name)\n                        classes.append({\"name\": node.name, \"methods\": methods})\n            except SyntaxError:\n                # Fallback regex for source code\n                for match in re.finditer(r\"class\\s+(\\w+).*?:\\s*(.*?)(?=class|def|$)\", content, re.DOTALL):\n                    class_name = match.group(1)\n                    methods = re.findall(r\"def\\s+(\\w+)\\s*\\(\", match.group(2))\n                    classes.append({\"name\": class_name, \"methods\": methods})\n        return classes\n\n# Usage Example\nif __name__ == \"__main__\":\n    summarizer = ProfessionalCodeSummarizer()\n    \n    # Analyze AST dump\n    ast_analysis = summarizer.analyze(\"/kaggle/input/app-python-dataset/app python.txt\")\n    print(\"=\"*80)\n    print(\"AST DUMP ANALYSIS RESULTS\")\n    print(\"=\"*80)\n    print(ast_analysis['structural'])\n    print(\"\\n\" + ast_analysis['functional'])\n    print(\"\\n💡 DEEP ANALYSIS:\")\n    print(ast_analysis['deep'])\n    \n    # Analyze source code\n    src_analysis = summarizer.analyze(\"/kaggle/input/app-python/app.py\")\n    print(\"\\n\" + \"=\"*80)\n    print(\"SOURCE CODE ANALYSIS RESULTS\")\n    print(\"=\"*80)\n    print(src_analysis['structural'])\n    print(\"\\n\" + src_analysis['functional'])\n    print(\"\\n💡 DEEP ANALYSIS:\")\n    print(src_analysis['deep'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-11T18:45:47.628763Z","iopub.execute_input":"2025-07-11T18:45:47.629237Z","iopub.status.idle":"2025-07-11T18:46:00.426148Z","shell.execute_reply.started":"2025-07-11T18:45:47.629200Z","shell.execute_reply":"2025-07-11T18:46:00.425097Z"}},"outputs":[{"name":"stdout","text":"✅ Loaded CodeT5-base model for code understanding\n================================================================================\nAST DUMP ANALYSIS RESULTS\n================================================================================\n🔍 STRUCTURAL ANALYSIS\n• Detected Imports: 3\n\n📦 KEY IMPORTS:\n  - os\n  - streamlit\n  - requests\n\n• Detected Functions: 0\n\n• Detected Classes: 0\n\n🚀 FUNCTIONAL SUMMARY\nThis appears to be a web application, API integration, system operations application with the following key components:\n\n💡 DEEP ANALYSIS:\nThe code implements API integration, handling remote service communication.\n\n================================================================================\nSOURCE CODE ANALYSIS RESULTS\n================================================================================\n🔍 STRUCTURAL ANALYSIS\n• Detected Imports: 4\n\n📦 KEY IMPORTS:\n  - from dotenv import load_dotenv\n  - import requests\n  - import streamlit\n  - import os\n\n• Detected Functions: 2\n\n🧰 CORE FUNCTIONS:\n  - generate_response(prompt, history)\n  - detect_language(text)\n\n• Detected Classes: 0\n\n🚀 FUNCTIONAL SUMMARY\nThis appears to be a web application, API integration, system operations application with the following key components:\n  - generate_response: Handles AI API communication and response generation\n  - detect_language: Identifies programming languages from text input\n\n💡 DEEP ANALYSIS:\nThe code implements API integration, handling remote service communication. State management is implemented using session-based storage. Error handling mechanisms are included for robustness. The system integrates with AI models for intelligent processing.\n","output_type":"stream"}],"execution_count":9}]}